{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_32116\\1865551121.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:/p/Iowa_Liquor_Sales.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('D:/p/Iowa_Liquor_Sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用特定的日期格式解析日期列\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# 筛选 2012 年到 2014 年之间的日期数据\n",
    "start_date = '2012-01-01'\n",
    "end_date = '2014-12-31'\n",
    "\n",
    "# 筛选数据框\n",
    "f_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Item Description  Bottles Sold\n",
      "100                             Absente             4\n",
      "102                    Cruzan Mango Rum             3\n",
      "103           Arrow Peppermint Schnapps             3\n",
      "104           Uv Blue (raspberry) Vodka            12\n",
      "106                       Kinky Liqueur            12\n",
      "...                                 ...           ...\n",
      "8197498             Cedar Ridge Bourbon             6\n",
      "8197500                   Tanqueray Gin             2\n",
      "8197501  Arrow Peppermint Schnapps Mini             1\n",
      "8197502                Cabo Wabo Blanco             6\n",
      "8197504   Jack Daniels Old #7 Black Lbl            12\n",
      "\n",
      "[6243618 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "selected_columns = ['Item Description', 'Bottles Sold']\n",
    "df_selected = f_df[selected_columns]\n",
    "print(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "grouped_df = df_selected.groupby('Item Description')['Bottles Sold'].sum().reset_index()\n",
    "sorted_df = grouped_df.sort_values(by='Bottles Sold', ascending=False).reset_index(drop=True)\n",
    "# print(sorted_df)\n",
    "# sorted_df.to_csv('D:/p/Iowa_Liquor_Sales_Sorted.csv', index=False)\n",
    "combined_df = pd.concat([sorted_df.head(10), sorted_df.tail(10)], ignore_index=True)\n",
    "# combined_df.to_csv('D:/p/Iowa_Liquor_Sales_f.csv', index=False)\n",
    "# print(combined_df)\n",
    "# print(sorted_df)\n",
    "combined_df_t = sorted_df.head(912)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Item Description  Bottles Sold    Z-score\n",
      "0                      Black Velvet       3116129  15.625319\n",
      "1                     Hawkeye Vodka       2407269  11.995246\n",
      "2         Captain Morgan Spiced Rum       1630743   8.018656\n",
      "3                Five O'clock Vodka       1602418   7.873604\n",
      "4     Jack Daniels Old #7 Black Lbl       1144380   5.527991\n",
      "5         Fireball Cinnamon Whiskey        928748   4.423740\n",
      "6               Mccormick Vodka Pet        873886   4.142791\n",
      "7             Smirnoff Vodka 80 Prf        871548   4.130818\n",
      "8                      Barton Vodka        858680   4.064921\n",
      "9       Crown Royal Canadian Whisky        794523   3.736373\n",
      "10             Bacardi Superior Rum        785503   3.690182\n",
      "11                   Phillips Vodka        778615   3.654909\n",
      "12             Jagermeister Liqueur        760497   3.562126\n",
      "13     Absolut Swedish Vodka 80 Prf        760446   3.561865\n",
      "14      Seagrams 7 Crown Bl Whiskey        741778   3.466266\n",
      "15  Paul Masson Grande Amber Brandy        699374   3.249115\n",
      "16                  Mccormick Vodka        669169   3.094436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_32116\\1390572098.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df_t['Z-score'] = np.abs(stats.zscore(combined_df_t['Bottles Sold']))\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Z-scores for 'Bottles Sold'\n",
    "combined_df_t['Z-score'] = np.abs(stats.zscore(combined_df_t['Bottles Sold']))\n",
    "\n",
    "# Identify outliers (Z-score > 3)\n",
    "outliers = combined_df_t[combined_df_t['Z-score'] > 3]\n",
    "\n",
    "# Print or display outliers\n",
    "print(outliers)\n",
    "\n",
    "# Optionally, remove outliers\n",
    "cleaned_df = combined_df_t[combined_df_t['Z-score'] <= 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_32116\\961838997.py:6: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  image_folder = 'D:\\p\\liquor_images'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore all warnings\n",
    "\n",
    "# 定义图片文件夹路径\n",
    "image_folder = 'D:\\p\\liquor_images'\n",
    "\n",
    "# 生成图片文件名列表\n",
    "image_filenames = [f'l{i}.png' for i in range(18, 913)]\n",
    "\n",
    "# 创建完整的图片路径列表\n",
    "image_paths = [os.path.join(image_folder, filename) for filename in image_filenames]\n",
    "\n",
    "# 将图片路径添加到 cleaned_df 数据框中\n",
    "cleaned_df['image_paths'] = image_paths\n",
    "cleaned_df.to_csv('D:/p/Iowa_Liquor_Sales_f.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "# Suppresses TensorFlow info and warnings, shows only errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Load pre-trained VGG16 model (without the top classification layer)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Function to suppress stdout (to hide the output during feature extraction)\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "def extract_features(img_path):\n",
    "    if os.path.exists(img_path):\n",
    "        # Load image and resize to (224, 224) as required by VGG16\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)  # Preprocess the image as expected by VGG16\n",
    "        \n",
    "        # Extract features using VGG16 model without progress bar (verbose=0)\n",
    "        features = model.predict(img_data, verbose=0)\n",
    "        return features.flatten()  # Flatten the features for further use\n",
    "    else:\n",
    "        print(f\"File not found: {img_path}\")\n",
    "        return None\n",
    "cleaned_df['image_paths'] = cleaned_df['image_paths'].str.replace('.png', '.jpg')\n",
    "# Apply feature extraction to your dataframe (assuming 'cleaned_df' has a column 'image_paths')\n",
    "cleaned_df['features'] = cleaned_df['image_paths'].apply(extract_features)\n",
    "\n",
    "# Optional: check extracted features\n",
    "# print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 512)\n",
      "(895,)\n"
     ]
    }
   ],
   "source": [
    "# 将特征和销售量数据提取成新的数据集\n",
    "features = np.array(cleaned_df['features'].tolist())\n",
    "sales = cleaned_df['Bottles Sold'].values\n",
    "sales_log = np.log1p(sales)\n",
    "# 检查特征和销售量的形状\n",
    "print(features.shape)\n",
    "print(sales_log.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "Mean Squared Error: 3.483029296866744\n",
      "      Actual  Predicted\n",
      "0   8.718827   8.806948\n",
      "1   9.519148  10.642384\n",
      "2   9.268137  10.409067\n",
      "3   8.689633   7.538166\n",
      "4  12.321858   9.524442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, sales_log, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=features_scaled.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=16, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Print a few predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred.flatten()  # Flatten to match dimensions\n",
    "})\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses TensorFlow info and warnings, shows only errors\n",
    "print(results_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 3.483029296866744\n",
      "Mean Absolute Error (MAE): 1.480341076684357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "# Calculate MSE, MAE, and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
